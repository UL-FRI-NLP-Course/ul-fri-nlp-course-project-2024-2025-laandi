import json

nlp_keywords = [
    # Core NLP Tasks
    "tokenization",
    "stemming",
    "lemmatization",
    "stop words",
    "part-of-speech tagging",
    "named entity recognition",
    "dependency parsing",
    "coreference resolution",
    "word sense disambiguation",
    "sentiment analysis",
    "topic modeling",
    "keyword extraction",
    "information extraction",
    "question answering",
    "text classification",
    "language modeling",
    "machine translation",
    "text summarization",
    "natural language generation",
    "natural language understanding",
    "entity linking",
    "relation extraction",
    "text segmentation",
    "discourse analysis",
    "semantic role labeling",
    "parsing",
    "anaphora resolution",
    "intent recognition",
    "dialogue systems",
    "chatbots",
    "speech recognition",
    "text-to-speech synthesis",
    "multilingual speech recognition",
    "post-editing in machine translation",
    "interactive machine translation",
    "adaptive machine translation",
    "domain-specific machine translation",
    "legal document translation",
    "medical document translation",
    "literary translation",
    "poetry translation",
    "subtitle generation",
    "closed captioning",
    "audiobook generation",
    "transcription",
    "real-time translation",
    "simultaneous interpretation",
    "consecutive interpretation",
    "sign language translation",
    "video captioning",
    "image captioning",
    "visual question answering",
    "scene description",
    "sentiment analysis",
    "cyberbullying detection",
    "online harassment monitoring",
    "reading comprehension systems",

    # Text Representation & Embeddings
    "bag of words",
    "n-grams",
    "TF-IDF",
    "word embeddings",
    "Word2Vec",
    "GloVe",
    "FastText",
    "contextual embeddings",
    "ELMo",
    "BERT",
    "GPT",
    "sentence embeddings",
    "universal sentence encoder",
    "vector space model",
    "semantic similarity",
    "transformers",
    "T5",
    "XLNet",
    "RoBERTa",
    "DistilBERT",
    "ALBERT",
    "ELECTRA",
    "ERNIE",
    "LLaMA",

    # Machine Learning & Deep Learning in NLP
    "sequence-to-sequence models",
    "transformer architecture",
    "attention mechanism",
    "self-attention",
    "encoder-decoder models",
    "pretrained language models",
    "fine-tuning",
    "recurrent neural networks",
    "long short-term memory",
    "gated recurrent units",
    "convolutional neural networks",
    "hidden Markov models",
    "conditional random fields",
    "naive Bayes classifier",
    "support vector machines",
    "decision trees",
    "random forests",
    "gradient boosting machines",
    "XGBoost",
    "lightGBM",
    "transfer learning in NLP",
    "cross-lingual transfer learning",
    "zero-resource language processing",
    "unsupervised machine translation",
    "pivot-based translation",
    "open-domain QA",
    "knowledge-grounded dialogue",
    "alignment with human preferences",
    "RLHF",
    "low-resource NLP",
    "data augmentation in NLP",
    "active learning for NLP",
    "semi-supervised learning in NLP",
    "unsupervised learning in NLP",
    "interactive NLP",
    "real-time NLP systems",
    "federated learning for NLP",

    # Linguistic Concepts
    "morphology",
    "syntax",
    "semantics",
    "pragmatics",
    "phonetics",
    "phonology",
    "discourse",
    "lexical semantics",
    "syntax-semantics interface",
    "semantic parsing",
    "controlled natural language",
    "context-free grammar",
    "probabilistic context-free grammar",
    "dependency grammar",
    "constituency grammar",
    "treebank",
    "corpus linguistics",
    "ontologies",
    "semantic web",
    "conceptual graphs",
    "language revitalization",
    "transliteration",
    "polyglot models",

    # Evaluation Metrics
    "BLEU score",
    "ROUGE score",
    "perplexity",
    "mean reciprocal rank",
    "normalized discounted cumulative gain",
    "word error rate",
    "METEOR",
    "TER",

    # Tools & Libraries
    "NLTK",
    "spaCy",
    "Gensim",
    "TextBlob",
    "CoreNLP",
    "OpenNLP",
    "AllenNLP",
    "Flair",
    "Transformers",
    "fastText",
    "Scikit-learn",
    "Keras",
    "TensorFlow",
    "PyTorch",
    "Hugging Face",
    "OpenAI API",
    "Google Cloud NLP",
    "AWS Comprehend",
    "Azure Text Analytics",
    "language resources",
    "corpora",
    "treebanks",
    "lexicons",
    "thesauri",
    "FrameNet",
    "PropBank",
    "VerbNet",
    "UMLS",
    "MeSH",
    "SNOMED CT",

    # Datasets & Benchmarks
    "Penn Treebank",
    "WordNet",
    "Wikipedia",
    "Common Crawl",
    "CoNLL",
    "SQuAD",
    "GLUE benchmark",
    "SuperGLUE",
    "MNLI",
    "SNLI",
    "TREC",
    "IMDB dataset",
    "Amazon Reviews",
    "Yelp Reviews",
    "20 Newsgroups",
    "Reuters-21578",
    "OpenSubtitles",
    "Europarl",
    "MultiWOZ",
    "GLUE",
    "XSum",
    "CNN/DailyMail",
    "CoNLL datasets",
    "OntoNotes",
    "CommonsenseQA",
    "Winograd Schema Challenge"

    # Applications
    "information retrieval",
    "search engines",
    "spell checking",
    "autocorrect",
    "autocomplete",
    "plagiarism detection",
    "text mining",
    "opinion mining",
    "social media analysis",
    "customer feedback analysis",
    "email filtering",
    "document classification",
    "language detection",
    "voice assistants",
    "machine reading comprehension",
    "fake news detection",
    "hate speech detection",
    "bias detection",
    "legal document analysis",
    "medical text analysis",
    "financial text analysis",
    "e-discovery",
    "chatbot development",
    "virtual assistants",
    "language tutoring systems",
    "text-based games",
    "interactive storytelling",
    "BioNLP",
    "Clinical NLP",
    "Financial NLP",
    "Legal NLP",
    "Social Media NLP",
    "NLP for education",
    "intelligent tutoring systems"

    # Advanced Topics
    "Ethics in NLP",
    "bias in language models",
    "interpretability",
    "explainable AI"
]


with open("nlp_tasks.json", "w") as f:
    json.dump(nlp_keywords, f)
